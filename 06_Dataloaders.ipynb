{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset:\n",
    "    def __init__(self,data,targets) -> None:\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        current_sample = self.data[idx,:]\n",
    "        current_target = self.targets[idx]\n",
    "        return {\n",
    "            \"x\" : torch.tensor(current_sample,dtype=torch.float),\n",
    "            \"y\" : torch.tensor(current_target,dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets =make_classification(n_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomDataset at 0x16eee131030>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CustomDataset(data,targets)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mT_co\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msampler\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSampler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mbatch_sampler\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSampler\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnum_workers\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcollate_fn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdrop_last\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mworker_init_fn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmultiprocessing_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mprefetch_factor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpersistent_workers\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpin_memory_device\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
      "the given dataset.\n",
      "\n",
      "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
      "iterable-style datasets with single- or multi-process loading, customizing\n",
      "loading order and optional automatic batching (collation) and memory pinning.\n",
      "\n",
      "See :py:mod:`torch.utils.data` documentation page for more details.\n",
      "\n",
      "Args:\n",
      "    dataset (Dataset): dataset from which to load the data.\n",
      "    batch_size (int, optional): how many samples per batch to load\n",
      "        (default: ``1``).\n",
      "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      "        at every epoch (default: ``False``).\n",
      "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
      "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
      "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
      "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
      "        returns a batch of indices at a time. Mutually exclusive with\n",
      "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
      "        and :attr:`drop_last`.\n",
      "    num_workers (int, optional): how many subprocesses to use for data\n",
      "        loading. ``0`` means that the data will be loaded in the main process.\n",
      "        (default: ``0``)\n",
      "    collate_fn (callable, optional): merges a list of samples to form a\n",
      "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
      "        map-style dataset.\n",
      "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
      "        into device/CUDA pinned memory before returning them.  If your data elements\n",
      "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
      "        see the example below.\n",
      "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
      "        the size of dataset is not divisible by the batch size, then the last batch\n",
      "        will be smaller. (default: ``False``)\n",
      "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      "        from workers. Should always be non-negative. (default: ``0``)\n",
      "    worker_init_fn (callable, optional): If not ``None``, this will be called on each\n",
      "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      "        input, after seeding and before data loading. (default: ``None``)\n",
      "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
      "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
      "        `base_seed` for workers. (default: ``None``)\n",
      "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
      "        in advance by each worker. ``2`` means there will be a total of\n",
      "        2 * num_workers batches prefetched across all workers. (default: ``2``)\n",
      "    persistent_workers (bool, optional): If ``True``, the data loader will not shutdown\n",
      "        the worker processes after a dataset has been consumed once. This allows to\n",
      "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
      "    pin_memory_device (str, optional): the data loader will copy Tensors\n",
      "        into device pinned memory before returning them if pin_memory is set to true.\n",
      "\n",
      "\n",
      ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
      "             cannot be an unpicklable object, e.g., a lambda function. See\n",
      "             :ref:`multiprocessing-best-practices` on more details related\n",
      "             to multiprocessing in PyTorch.\n",
      "\n",
      ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
      "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
      "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
      "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
      "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
      "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
      "             loading to avoid duplicate data.\n",
      "\n",
      "             However, if sharding results in multiple workers having incomplete last batches,\n",
      "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
      "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
      "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
      "             cases in general.\n",
      "\n",
      "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
      "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
      "             `Multi-process data loading`_.\n",
      "\n",
      ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
      "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\nikhi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "?torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset,batch_size=4,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x16eb08f7fd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_loader:\n",
    "    print(data['x'].shape) \n",
    "    print(data['y'].shape) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    for data in train_loader:\n",
    "        x= data['x']\n",
    "        y= data['y']\n",
    "        output = model(x,y)\n",
    "        ## loss = ...\n",
    "        ## loss.backwards()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49925a85a85dac8a2dca5afbebde9d93135fdd4b812dbf89ef8044a5eedbb9bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
